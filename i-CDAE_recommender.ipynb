{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-884f33e4e29e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os.path\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "#sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "wk_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "print(wk_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation is viewed as information retrieval task: Retrieve (recommend) all items which are predicted to be “good”.\n",
    "\n",
    "Precision: a measure of exactness, determines the fraction of relevant items retrieved out of all items retrieved\n",
    "Recall: a measure of completeness, determines the fraction of relevant items retrieved out of all relevant items\n",
    "typically when a recommender system is tuned to increase precision, recall decreases as a result (or vice versa)\n",
    "The F1 Metric attempts to combine Precision and Recall into a single value for comparison purposes. The F1 Metric gives equal weight to precision and recall\n",
    "\n",
    "Rank metrics extend recall and precision to take the positions of correct items in a ranked list into account\n",
    "Relevant items are more useful when they appear earlier in the recommendation list\n",
    "Particularly important in recommender systems as lower ranked items may be overlooked by users\n",
    "\n",
    "Discounted cumulative gain (DCG) is a measure of ranking quality. In information retrieval, it is often used to measure effectiveness of web search engine algorithms or related applications. Using a graded relevance scale of documents in a search-engine result set, DCG measures the usefulness, or gain, of a document based on its position in the result list. The gain is accumulated from the top of the result list to the bottom, with the gain of each result discounted at lower ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# efficient version\n",
    "def precision_recall_ndcg_at_k(k, rankedlist, test_matrix):\n",
    "    idcg_k = 0\n",
    "    dcg_k = 0\n",
    "    n_k = k if len(test_matrix) > k else len(test_matrix)\n",
    "    for i in range(n_k):\n",
    "        idcg_k += 1 / math.log(i + 2, 2)\n",
    "\n",
    "    b1 = rankedlist\n",
    "    b2 = test_matrix\n",
    "    s2 = set(b2)\n",
    "    hits = [(idx, val) for idx, val in enumerate(b1) if val in s2]\n",
    "    count = len(hits)\n",
    "\n",
    "    for c in range(count):\n",
    "        dcg_k += 1 / math.log(hits[c][0] + 2, 2)\n",
    "\n",
    "    return float(count / k), float(count / len(test_matrix)), float(dcg_k / idcg_k)\n",
    "\n",
    "\n",
    "def map_mrr_ndcg(rankedlist, test_matrix):\n",
    "    ap = 0\n",
    "    map = 0\n",
    "    dcg = 0\n",
    "    idcg = 0\n",
    "    mrr = 0\n",
    "    for i in range(len(test_matrix)):\n",
    "        idcg += 1 / math.log(i + 2, 2)\n",
    "\n",
    "    b1 = rankedlist\n",
    "    b2 = test_matrix\n",
    "    s2 = set(b2)\n",
    "    hits = [(idx, val) for idx, val in enumerate(b1) if val in s2]\n",
    "    count = len(hits)\n",
    "\n",
    "    for c in range(count):\n",
    "        ap += (c + 1) / (hits[c][0] + 1)\n",
    "        dcg += 1 / math.log(hits[c][0] + 2, 2)\n",
    "\n",
    "    if count != 0:\n",
    "        mrr = 1 / (hits[0][0] + 1)\n",
    "\n",
    "    if count != 0:\n",
    "        map = ap / count\n",
    "\n",
    "    return map, mrr, float(dcg / idcg)\n",
    "\n",
    "\n",
    "def evaluate(self):\n",
    "    pred_ratings_10 = {}\n",
    "    pred_ratings_5 = {}\n",
    "    pred_ratings = {}\n",
    "    ranked_list = {}\n",
    "    p_at_5 = []\n",
    "    p_at_10 = []\n",
    "    r_at_5 = []\n",
    "    r_at_10 = []\n",
    "    map = []\n",
    "    mrr = []\n",
    "    ndcg = []\n",
    "    ndcg_at_5 = []\n",
    "    ndcg_at_10 = []\n",
    "    for u in self.test_users:\n",
    "        user_ids = []\n",
    "        user_neg_items = self.neg_items[u]\n",
    "        item_ids = []\n",
    "        # scores = []\n",
    "        for j in user_neg_items:\n",
    "            item_ids.append(j)\n",
    "            user_ids.append(u)\n",
    "\n",
    "        scores = self.predict(user_ids, item_ids)\n",
    "        # print(type(scores))\n",
    "        # print(scores)\n",
    "        # print(np.shape(scores))\n",
    "        # print(ratings)\n",
    "        neg_item_index = list(zip(item_ids, scores))\n",
    "\n",
    "        ranked_list[u] = sorted(neg_item_index, key=lambda tup: tup[1], reverse=True)\n",
    "        pred_ratings[u] = [r[0] for r in ranked_list[u]]\n",
    "        pred_ratings_5[u] = pred_ratings[u][:5]\n",
    "        pred_ratings_10[u] = pred_ratings[u][:10]\n",
    "\n",
    "        p_5, r_5, ndcg_5 = precision_recall_ndcg_at_k(5, pred_ratings_5[u], self.test_data[u])\n",
    "        p_at_5.append(p_5)\n",
    "        r_at_5.append(r_5)\n",
    "        ndcg_at_5.append(ndcg_5)\n",
    "        p_10, r_10, ndcg_10 = precision_recall_ndcg_at_k(10, pred_ratings_10[u], self.test_data[u])\n",
    "        p_at_10.append(p_10)\n",
    "        r_at_10.append(r_10)\n",
    "        ndcg_at_10.append(ndcg_10)\n",
    "        map_u, mrr_u, ndcg_u = map_mrr_ndcg(pred_ratings[u], self.test_data[u])\n",
    "        map.append(map_u)\n",
    "        mrr.append(mrr_u)\n",
    "        ndcg.append(ndcg_u)\n",
    "\n",
    "    print(\"------------------------\")\n",
    "    print(\"precision@10:\" + str(np.mean(p_at_10)))\n",
    "    print(\"recall@10:\" + str(np.mean(r_at_10)))\n",
    "    print(\"precision@5:\" + str(np.mean(p_at_5)))\n",
    "    print(\"recall@5:\" + str(np.mean(r_at_5)))\n",
    "    print(\"map:\" + str(np.mean(map)))\n",
    "    print(\"mrr:\" + str(np.mean(mrr)))\n",
    "    print(\"ndcg:\" + str(np.mean(ndcg)))\n",
    "    print(\"ndcg@5:\" + str(np.mean(ndcg_at_5)))\n",
    "    print(\"ndcg@10:\" + str(np.mean(ndcg_at_10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ICDAE():\n",
    "    '''\n",
    "    Based on CDAE and I-AutoRec, I designed the following item based CDAE, it seems to perform better than CDAE slightly.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, sess, num_user, num_item, learning_rate=0.01, reg_rate=0.01, epoch=500, batch_size=300,\n",
    "                 verbose=False, T=2, display_step=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.reg_rate = reg_rate\n",
    "        self.sess = sess\n",
    "        self.num_user = num_user\n",
    "        self.num_item = num_item\n",
    "        self.verbose = verbose\n",
    "        self.T = T\n",
    "        self.display_step = display_step\n",
    "        print(\"Item based CDAE.\")\n",
    "\n",
    "    def build_network(self, hidden_neuron=500, corruption_level=0):\n",
    "        self.corrupted_interact_matrix = tf.placeholder(dtype=tf.float32, shape=[None, self.num_user])\n",
    "        self.interact_matrix = tf.placeholder(dtype=tf.float32, shape=[None, self.num_user])\n",
    "        self.item_id = tf.placeholder(dtype=tf.int32, shape=[None])\n",
    "        self.corruption_level = corruption_level\n",
    "\n",
    "        W = tf.Variable(tf.random_normal([self.num_user, hidden_neuron], stddev=0.01))\n",
    "        W_prime = tf.Variable(tf.random_normal([hidden_neuron, self.num_user], stddev=0.01))\n",
    "        V = tf.Variable(tf.random_normal([self.num_item, hidden_neuron], stddev=0.01))\n",
    "\n",
    "        b = tf.Variable(tf.random_normal([hidden_neuron], stddev=0.01))\n",
    "        b_prime = tf.Variable(tf.random_normal([self.num_user], stddev=0.01))\n",
    "        # print(np.shape(tf.matmul(self.corrupted_interact_matrix, W)))\n",
    "        # print(np.shape( tf.nn.embedding_lookup(V, self.item_id)))\n",
    "        layer_1 = tf.sigmoid(tf.matmul(self.corrupted_interact_matrix, W) + b)\n",
    "        self.layer_2 = tf.sigmoid(tf.matmul(layer_1, W_prime) + b_prime)\n",
    "\n",
    "        self.loss = - tf.reduce_sum(\n",
    "            self.interact_matrix * tf.log(self.layer_2) + (1 - self.interact_matrix) * tf.log(1 - self.layer_2)) \\\n",
    "                    + self.reg_rate * (\n",
    "        tf.nn.l2_loss(W) + tf.nn.l2_loss(W_prime) + tf.nn.l2_loss(b) + tf.nn.l2_loss(b_prime))\n",
    "\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.loss)\n",
    "\n",
    "    def prepare_data(self, train_data, test_data):\n",
    "        self.train_data = self._data_process(train_data).transpose()\n",
    "        self.neg_items = self._get_neg_items(train_data)\n",
    "        self.num_training = self.num_item\n",
    "        self.total_batch = int(self.num_training / self.batch_size)\n",
    "        self.test_data = test_data\n",
    "        self.test_users = set([u for u in self.test_data.keys() if len(self.test_data[u]) > 0])\n",
    "        print(\"data preparation finished.\")\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        idxs = np.random.permutation(self.num_training)  # shuffled ordering\n",
    "\n",
    "        for i in range(self.total_batch):\n",
    "            start_time = time.time()\n",
    "            if i == self.total_batch - 1:\n",
    "                batch_set_idx = idxs[i * self.batch_size:]\n",
    "            elif i < self.total_batch - 1:\n",
    "                batch_set_idx = idxs[i * self.batch_size: (i + 1) * self.batch_size]\n",
    "\n",
    "            _, loss = self.sess.run([self.optimizer, self.loss], feed_dict={\n",
    "                self.corrupted_interact_matrix: self._get_corrupted_input(self.train_data[batch_set_idx, :],\n",
    "                                                                          self.corruption_level),\n",
    "                self.interact_matrix: self.train_data[batch_set_idx, :],\n",
    "                self.item_id: batch_set_idx\n",
    "                })\n",
    "            if self.verbose and i % self.display_step == 0:\n",
    "                print(\"Index: %04d; cost= %.9f\" % (i + 1, np.mean(loss)))\n",
    "                if self.verbose:\n",
    "                    print(\"one iteration: %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "    def test(self):\n",
    "        self.reconstruction = self.sess.run(self.layer_2, feed_dict={self.corrupted_interact_matrix: self.train_data,\n",
    "                                                                     self.item_id: range(self.num_item)}).transpose()\n",
    "\n",
    "        evaluate(self)\n",
    "\n",
    "    def execute(self, train_data, test_data):\n",
    "        self.prepare_data(train_data, test_data)\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "        for epoch in range(self.epochs):\n",
    "            self.train()\n",
    "            if (epoch) % self.T == 0:\n",
    "                print(\"Epoch: %04d; \" % (epoch), end='')\n",
    "                self.test()\n",
    "            \n",
    "\n",
    "    def save(self, path):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(self.sess, path)\n",
    "\n",
    "    def predict(self, user_id, item_id):\n",
    "        return np.array(self.reconstruction[np.array(user_id), np.array(item_id)])\n",
    "\n",
    "    def _data_process(self, data):\n",
    "        return np.asmatrix(data)\n",
    "\n",
    "    def _get_neg_items(self, data):\n",
    "        neg_items = {}\n",
    "        for u in range(self.num_user):\n",
    "            neg_items[u] = [k for k, i in enumerate(data[u]) if data[u][k] == 0]\n",
    "            # print(neg_items[u])\n",
    "\n",
    "        return neg_items\n",
    "\n",
    "    def _get_corrupted_input(self, input, corruption_level):\n",
    "        return np.random.binomial(n=1, p=1 - corruption_level) * input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_all(path=\"../data/ml100k/movielens_100k.dat\", header=['user_id', 'item_id', 'rating', 'time'],\n",
    "                  test_size=0.2, sep=\"\\t\"):\n",
    "    df = pd.read_csv(path, sep=sep, names=header, engine='python')\n",
    "\n",
    "    n_users = df.user_id.unique().shape[0]\n",
    "    n_items = df.item_id.unique().shape[0]\n",
    "\n",
    "    train_data, test_data = train_test_split(df, test_size=test_size)\n",
    "    train_data = pd.DataFrame(train_data)\n",
    "    test_data = pd.DataFrame(test_data)\n",
    "    \n",
    "    print(train_data.head)\n",
    "    print(test_data.head)\n",
    "    train_row = []\n",
    "    train_col = []\n",
    "    train_rating = []\n",
    "\n",
    "    train_dict = {}\n",
    "    for line in train_data.itertuples():\n",
    "        u = line[1] - 1\n",
    "        i = line[2] - 1\n",
    "        train_dict[(u, i)] = 1\n",
    "\n",
    "    for u in range(n_users):\n",
    "        for i in range(n_items):\n",
    "            train_row.append(u)\n",
    "            train_col.append(i)\n",
    "            if (u, i) in train_dict.keys():\n",
    "                train_rating.append(1)\n",
    "            else:\n",
    "                train_rating.append(0)\n",
    "    train_matrix = csr_matrix((train_rating, (train_row, train_col)), shape=(n_users, n_items))\n",
    "    all_items = set(np.arange(n_items))\n",
    "\n",
    "    neg_items = {}\n",
    "    train_interaction_matrix = []\n",
    "    for u in range(n_users):\n",
    "        neg_items[u] = list(all_items - set(train_matrix.getrow(u).nonzero()[1]))\n",
    "        train_interaction_matrix.append(list(train_matrix.getrow(u).toarray()[0]))\n",
    "\n",
    "    test_row = []\n",
    "    test_col = []\n",
    "    test_rating = []\n",
    "    for line in test_data.itertuples():\n",
    "        test_row.append(line[1] - 1)\n",
    "        test_col.append(line[2] - 1)\n",
    "        test_rating.append(1)\n",
    "    test_matrix = csr_matrix((test_rating, (test_row, test_col)), shape=(n_users, n_items))\n",
    "\n",
    "    test_dict = {}\n",
    "    for u in range(n_users):\n",
    "        test_dict[u] = test_matrix.getrow(u).nonzero()[1]\n",
    "\n",
    "    print(\"Load data finished. Number of users:\", n_users, \"Number of items:\", n_items)\n",
    "\n",
    "    return train_interaction_matrix, test_dict, n_users, n_items\n",
    "\n",
    "\n",
    "def load_data_neg(path=\"../data/ml100k/movielens_100k.dat\", header=['user_id', 'item_id', 'rating', 'category'],\n",
    "                  test_size=0.2, sep=\"\\t\"):\n",
    "    df = pd.read_csv(path, sep=sep, names=header, engine='python')\n",
    "\n",
    "    n_users = df.user_id.unique().shape[0]\n",
    "    n_items = df.item_id.unique().shape[0]\n",
    "\n",
    "    train_data, test_data = train_test_split(df, test_size=test_size)\n",
    "    train_data = pd.DataFrame(train_data)\n",
    "    \n",
    "    test_data = pd.DataFrame(test_data)\n",
    "    print(test_data.head)\n",
    "    train_row = []\n",
    "    train_col = []\n",
    "    train_rating = []\n",
    "\n",
    "    for line in train_data.itertuples():\n",
    "        u = line[1] - 1\n",
    "        i = line[2] - 1\n",
    "        train_row.append(u)\n",
    "        train_col.append(i)\n",
    "        train_rating.append(line[3])\n",
    "    train_matrix = csr_matrix((train_rating, (train_row, train_col)), shape=(n_users, n_items))\n",
    "\n",
    "    # all_items = set(np.arange(n_items))\n",
    "    # neg_items = {}\n",
    "    # for u in range(n_users):\n",
    "    #     neg_items[u] = list(all_items - set(train_matrix.getrow(u).nonzero()[1]))\n",
    "\n",
    "    test_row = []\n",
    "    test_col = []\n",
    "    test_rating = []\n",
    "    for line in test_data.itertuples():\n",
    "        test_row.append(line[1] - 1)\n",
    "        test_col.append(line[2] - 1)\n",
    "        test_rating.append(line[3])\n",
    "    test_matrix = csr_matrix((test_rating, (test_row, test_col)), shape=(n_users, n_items))\n",
    "\n",
    "    test_dict = {}\n",
    "    for u in range(n_users):\n",
    "        test_dict[u] = test_matrix.getrow(u).nonzero()[1]\n",
    "\n",
    "    print(\"Load data finished. Number of users:\", n_users, \"Number of items:\", n_items)\n",
    "    return train_matrix.todok(), test_dict, n_users, n_items\n",
    "\n",
    "\n",
    "def load_data_separately(path_train=None, path_test=None, path_val=None, header=['user_id', 'item_id', 'rating'],\n",
    "                         sep=\" \", n_users=0, n_items=0):\n",
    "    n_users = n_users\n",
    "    n_items = n_items\n",
    "    print(\"start\")\n",
    "    train_matrix = None\n",
    "    if path_train is not None:\n",
    "        train_data = pd.read_csv(path_train, sep=sep, names=header, engine='python')\n",
    "        print(\"Load data finished. Number of users:\", n_users, \"Number of items:\", n_items)\n",
    "\n",
    "        train_row = []\n",
    "        train_col = []\n",
    "        train_rating = []\n",
    "\n",
    "        for line in train_data.itertuples():\n",
    "            u = line[1]  # - 1\n",
    "            i = line[2]  # - 1\n",
    "            train_row.append(u)\n",
    "            train_col.append(i)\n",
    "            train_rating.append(1)\n",
    "\n",
    "        train_matrix = csr_matrix((train_rating, (train_row, train_col)), shape=(n_users, n_items))\n",
    "\n",
    "    print(\"Load data finished. Number of users:\", n_users, \"Number of items:\", n_items)\n",
    "    test_dict = None\n",
    "    if path_test is not None:\n",
    "        test_data = pd.read_csv(path_test, sep=sep, names=header, engine='python')\n",
    "        test_row = []\n",
    "        test_col = []\n",
    "        test_rating = []\n",
    "        for line in test_data.itertuples():\n",
    "            test_row.append(line[1])\n",
    "            i = line[2]  # - 1\n",
    "            test_col.append(i)\n",
    "            test_rating.append(1)\n",
    "\n",
    "        test_matrix = csr_matrix((test_rating, (test_row, test_col)), shape=(n_users, n_items))\n",
    "\n",
    "        test_dict = {}\n",
    "        for u in range(n_users):\n",
    "            test_dict[u] = test_matrix.getrow(u).nonzero()[1]\n",
    "    all_items = set(np.arange(n_items))\n",
    "    train_interaction_matrix = []\n",
    "    for u in range(n_users):\n",
    "        train_interaction_matrix.append(list(train_matrix.getrow(u).toarray()[0]))\n",
    "\n",
    "    if path_val is not None:\n",
    "        val_data = pd.read_csv(path_val, sep=sep, names=header, engine='python')\n",
    "\n",
    "    print(\"end\")\n",
    "    return train_interaction_matrix, test_dict, n_users, n_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model ='CDAE'\n",
    "epochs = 1000\n",
    "num_factors = 10\n",
    "display_step = 1000\n",
    "batch_size = 1024  # 128 for unlimpair\n",
    "learning_rate = 1e-3  # 1e-4 for unlimpair\n",
    "reg_rate = 0.1  # 0.01 for unlimpair\n",
    "train_data, test_data, n_user, n_item = load_data_all(test_size=0.2, sep=\"\\t\")\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    model = ICDAE(sess, n_user, n_item)\n",
    "    model.build_network()\n",
    "    model.execute(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
